# datasets/ 運用ルール

## 目的
- 画像データの「原本」「正規化済み」「採用（picked）」「学習投入（staging）」を分離し、
  事故（上書き/混入/取り違え）を防ぐ。
- Git は「再現手順と設定」を管理し、巨大な生成物・データは基本的に管理しない。

---

## ディレクトリ構成（推奨）

datasets/
  raw/           # 収集した原本（手を加えない）
  normalized/    # SDが読みやすい形に正規化したもの（リサイズ/EXIF補正/形式統一など）
  picked/        # 人間が採用したもの（自己蒸留の入口・最重要）
  staging/       # 学習投入用に自動生成した最終形（一時・再生成可能）

---

## 各ディレクトリの扱い

### datasets/raw/
- 役割: 収集した画像の「原本保管庫」
- ルール:
  - 原則として編集しない（後でやり直すためのソース）
  - 巨大化しやすいので Git 管理しない（gitignore推奨）
  - 容量が大きい場合は外部ストレージに置き、symlink で接続してもよい

### datasets/normalized/
- 役割: SD/LoRA 学習に適した形式へ変換した「素材」
- 例: リサイズ、アスペクト比除外、EXIF回転補正、拡張子統一、RGB化など
- ルール:
  - raw から生成される中間生成物
  - 基本は Git 管理しない（gitignore推奨）
  - 正規化の仕様（target-long / min-short / max-ar 等）は configs と scripts に残す

### datasets/picked/
- 役割: 人間が「良い」と判断して採用した画像だけを入れる入口
- ルール:
  - 人間が触ってよい唯一の場所（基本はここへの移動だけ）
  - ここに入った画像が “学習の意思” を表す
  - Git 管理は非推奨（容量・権利・更新頻度の問題）
    - 推奨: picked の **マニフェスト（ファイル名+hash一覧）** を別途出力して Git 管理する

### datasets/staging/
- 役割: 学習に投入する最終形（自動生成）
- ルール:
  - `make stage` 等のコマンドで picked から生成する
  - 常に再生成可能にする（Git 管理しない）
  - staging 生成時に dataset_hash を計算し、学習 meta に記録する

---

## データの流れ（原則）

raw → normalized →（人間が選別）→ picked →（自動生成）→ staging → train

- 正規化の入力と出力は datasets 内で完結させる。
- 学習は staging のみを参照する（picked を直接食わせない）ことで、再現性と事故耐性を上げる。

---

## Git / バックアップ方針
- datasets 配下の画像データは基本 gitignore。
- どうしても履歴を残したい場合:
  - 画像本体は外部ストレージ or DVC/annex 等で管理
  - Git には以下を残す:
    - 正規化・ステージング生成のコード
    - configs（変換条件/学習条件）
    - picked_manifest.json（任意）

---

## 実行環境に関する注意
- Python スクリプト（例: リサイズ/ステージング生成）は **venv 環境で実行**すること。
- ComfyUI は Docker 環境を前提とし、制御スクリプト（venv）と生成環境（Docker）を混線させない。
  - 生成物の受け渡しは「ボリュームマウントされたディレクトリ」を介して行う。
